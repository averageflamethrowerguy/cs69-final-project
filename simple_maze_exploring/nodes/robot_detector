#!/usr/bin/env python
#The line above is important so that this file is interpreted with Python when running it.

# Import of python modules.
import math # use of pi.
import random #use for random colision avoidance angle

# import of relevant libraries.
import rospy # module for ROS APIs
from geometry_msgs.msg import PoseStamped # message type for cmd_vel
from sensor_msgs.msg import LaserScan, Image # message type for scan
from nav_msgs.msg import Odometry, Path
from std_msgs.msg import Float32
from tf.transformations import quaternion_from_euler
from std_msgs.msg import String
import json
import tf
import numpy as np


#camera specific imports
import matplotlib.pyplot as plt
from cv_bridge import CvBridge
import cv2

# Constants.
FREQUENCY = 10 #Hz.
LINEAR_VELOCITY = 0.1 #/ FACTOR # m/s
ANGULAR_VELOCITY = math.pi / 8 #/ FACTOR # rad/s
LASER_ANGLE_FRONT = 0 # radians
MIN_THRESHOLD_DISTANCE = 0.5 # m, threshold distance.
DEFAULT_CMD_VEL_TOPIC = 'cmd_vel'
DEFAULT_SCAN_TOPIC = 'scan'
ROBOT_MERGE_TOPIC = "/merge"

colors = {0: [255, 0, 0, 255], 1: [0, 255, 0, 255]}

class Broadcast():
    def __init__(self, num_robots, robot_id):
        self._num_robots = num_robots
        self._robot_id = robot_id
        self._image_sub = rospy.Subscriber(rospy.get_namespace() + "image", Image, self._image_cb)
        self._merge_signaller = rospy.Publisher(ROBOT_MERGE_TOPIC, String, queue_size=1)

        rospy.spin()

    def _find_robot(self, image, robot_id):
        lower = np.clip(colors[robot_id] + np.array([-20, -20, -20, 0]), np.ones(4) * 0,  np.ones(4) * 255).astype(np.uint8)
        upper = np.clip(colors[robot_id] + np.array([20, 20, 20, 0]), np.ones(4) * 0, np.ones(4) * 255).astype(np.uint8)
        
        # print(image, tuple(upper), tuple(lower))
        mask = cv2.inRange(image, lower, upper)
    
        image = cv2.bitwise_and(image, image, mask=mask)

        contours, hierarchy, _ = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        output = cv2.drawContours(image, hierarchy, -1, (255, 255, 0, 255), 4)
        
        # Showing the output
        if np.any(image[image > 0]):
            plt.imshow(output)
            plt.show()
            cv2.waitKey(30)

        return np.any(image[image > 0])

    def _image_cb(self, msg):
        #print(msg)
        bridge = CvBridge()
        try:
            cv_image = bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')
        except CvBridgeError as e:
            print(e)
        (rows,cols,channels) = cv_image.shape
        if cols > 60 and rows > 60:
            cv2.circle(cv_image, (50,50), 10, 255)
        
        for i in range(self._num_robots):
            found = self._find_robot(cv_image, i)
            print("FOUND ROBOT [",i,"]:", found)
            msg_obj = {"robot_ids": [i, self._robot_id]}
            json_msg = json.dumps(msg_obj)
            string_msg = String()
            string_msg.data = json_msg
            self._merge_signaller.publish(string_msg)
        

    def run(self):
        pass

def main():
    """Main function."""

    # 1st. initialization of node.
    rospy.init_node("robot_detector")

    # Sleep for a few seconds to wait for the registration.
    rospy.sleep(2)

    num_robots = int(rospy.get_param("/num_robots"))
    # robot_id_outer = rospy.get_param("robot_id")
    robot_id_outer = 0

    broadcast_node = Broadcast(num_robots, robot_id_outer)
    try:
        broadcast_node.run()
    except rospy.ROSInterruptException:
        rospy.logerr("ROS node interrupted.")

if __name__ == "__main__":
    """Run the main function."""
    main()